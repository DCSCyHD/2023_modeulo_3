---
title: "Práctica 3 - Módulo 3"
subtitle: "Regresión lineal simple y múltiple"
author: 
  - Diplomatura en Ciencias Sociales Computacionales y Humanidades Digitales (IDAES-UNSAM).
output: 
  html_document:
    toc: TRUE
    toc_float:
      toc_collapsed: true
    toc_depth: 3
    number_sections: true
    theme: readable
editor_options: 
  chunk_output_type: console
---

> Material elaborado originalmente por Carolina Pradier y Guido Weksler

```{r setup, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
knitr::opts_chunk$set(
  echo=TRUE, 
  message=TRUE, 
  warning=FALSE, 
  tidy=FALSE,
  fig.width=8)
```

```{r librerias, results='hide', message=FALSE, warning=FALSE}
library(tidyverse)
library(tidymodels)
library(viridis)
library(car)
library(performance)
tidymodels_prefer()

options(dplyr.summarise.inform = FALSE)
```

# Introducción

Vamos a seguir trabajando con nuestra base de juguete para construir una regresión lineal múltiple.

```{r}
base_juguete <- readRDS("./fuentes/eut_juguete.RDS")
```

# Regresión lineal simple

En la clase anterior habíamos llegado a esta regresión lineal simple, pero notábamos que nuestro modelo tenía problemas para explicar algunos de los valores. Vamos a intentar mejorarlo agregando más información con otras variables.

```{r}
lm_model <- linear_reg() %>%
  set_mode("regression") %>%
  set_engine("lm")
```

```{r}
lm_fit <- lm_model %>%
  fit(ingreso_individual ~ horas_trabajo_domestico,
      data = base_juguete)
```

# Regresión lineal múltiple

Antes de empezar, chequeamos multicolinealidad con la función vif() del paquete *car*. 

```{r}
lm_vif <- lm(ingreso_individual ~ . , #Con . indicamos "todas las demas"
               data = base_juguete)

# Calculo vif (variance inflation factor)
vif(lm_vif)

# Lo miro con un plot
vif(lm_vif) %>% data.frame() %>% 
  rownames_to_column(var="variable") %>% 
  ggplot(aes(x=variable,y=.))+
  geom_col(fill="#00BFC4")+
  geom_hline(yintercept = 5, linetype = "dashed")+
  coord_flip()+
  theme_minimal()

```

En todos los casos los valores son bajos, por lo que podemos incorporar todas las variables que nos parezcan relevantes. Probemos con todas:

```{r}
lm_fit2 <- lm_model %>%
  fit(formula = ingreso_individual ~ ., #Con "." indicamos "todas las demás"
      data = base_juguete)
```

Notemos cómo tidymodels nos permite aplicar fácilmente el modelo que estamos trabajando (lm_model) a distintas fórmulas. Veamos los coeficientes y la significatividad de las relaciones.

```{r}
lm_fit2 %>% 
  pluck("fit") %>%
  summary()
```

La variable realiza_trabajo_domestico no es significativa para analizar el nivel de ingresos. Esto es esperable, dado que la variable *horas_trabajo_domestico* ya incluye la información de la variable *realiza_trabajo_domestico* (valores positivos indican Sí). Por esta razón, se excluye del modelo. Entonces, la ecuación que caracterizaría nuestro modelo es:

$$ IngInd = \beta_{0} + \beta_{1}HorasTD + \beta_{2}HorasM + \beta_{3}Sexo + \beta_{4}Menores + \epsilon$$

```{r}
#planteamos el nuevo modelo
lm_fit2 <- lm_model %>%
  fit(ingreso_individual ~ horas_trabajo_domestico + 
                           horas_trabajo_mercado + 
                           sexo + 
                           menores_hogar,
    data = base_juguete)

#y vemos los coeficientes
lm_fit2 %>%
  pluck("fit") %>%
  summary()
```

Noten que mejora el $R^{2}$ **ajustado**.

Veamos la distribución de los residuos:

```{r}
#calculamos
lm_fit2 %>% 
  augment(new_data = base_juguete) %>%
  dplyr::select(.resid, .pred) %>%
  #graficamos
  ggplot(aes(x = .pred, y = .resid)) +
    geom_point() +
    theme_minimal() +
    geom_hline(yintercept = 0, linetype = 'dashed') 
```

Al observar cómo quedan los residuos, vemos que esta vez el modelo está funcionando mejor que la última vez, la distribución parece ser bastante aleatoria. Veamos si podemos seguir mejorando.

# Agregamos una interacción

Algo que podría ocurrir es que el efecto sobre los ingresos de trabajar de modo remunerado en el mercado sea distinto para las mujeres y los varones: probemos agregar una interacción. Al agregarla, nuestra ecuación pasaría a tomar la forma:

$$ IngInd = \beta_{0} + \beta_{1}HorasTD + \beta_{2}HorasM + \beta_{3}Sexo + \beta_{4}Menores + \beta_{5}HorasM.Sexo + \epsilon$$

```{r}
#usamos los ":" para agregar la interacción
lm_fit3 <- lm_model %>%
  fit(ingreso_individual ~ horas_trabajo_domestico +
                         sexo:horas_trabajo_mercado +
                         horas_trabajo_mercado + 
                         sexo + 
                         menores_hogar,
    data = base_juguete)
```

Veamos los coeficientes:

```{r}
lm_fit3 %>% 
  pluck("fit") %>%
  summary()
```

No sólo es significativo el coeficiente de la interacción, sino que además mejoraró el $R^{2}$ ajustado.

# Transformar variables en workflows (feature engineering) 

El herramental de tidymodels nos permite aplicar distintas transformaciones sobre nuestros datos antes de estimar los coeficientes. La lógica de tidymodels nos permite separar este paso de aquel de especificación del modelo.

Una sintáxis más general para los pasos que aplicamos anteriormente es usar un *workflow.* Es decir, dentro de un workflow, especificamos primero el modelo, luego la fórmula o "receta" de las transformaciones que vamos a hacer a las variables, finalmente estimamos. La gracia de hacer estos pasos por separado es que cada uno es una etapa del proceso de modelado, que merece su propio proceso y que, como vamos a ver, podemos querer combinar de distintas maneras con los otros pasos. 

Podemos consultar la presentación de Tidymodels a modo de _cheatsheet_ de cómo funcionan los workflows.

Primero agregamos un modelo:

```{r}
lm_wflow <- workflow() %>% 
  add_model(lm_model)
```

Luego agregamos la fórmula:

```{r}
lm_wflow <- lm_wflow %>% 
  add_formula(ingreso_individual ~ horas_trabajo_domestico + 
                                   sexo:horas_trabajo_mercado +
                                   horas_trabajo_mercado + 
                                   sexo + 
                                   menores_hogar
  )
```

Y finalmente estimamos:

```{r}
lm_fit3 <- lm_wflow %>% 
  fit(base_juguete)
```

Veamos los coeficientes y la significatividad. Una forma fácil de hacerlo es directo con `tidy()`.

```{r}
lm_fit3 %>% tidy()
```

Pero para extraer los resultados completos después de aplicar fit a un workflow usamos la función `extract_fit_engine()`, que nos devuelve el objeto `lm` subyacente.

```{r}
lm_fit3 %>%
  extract_fit_engine() %>% 
  summary() #%>% tidy()
```

En vez de una fórmula, para definir los predictores y las **transformaciones** que queremos aplicarles podemos usar *recipe().* A esto lo llamamos "preprocesamiento" (porque lo hacemos antes de estimar).

Las transformaciones se aplican encadenando comandos *step_xxx()* que se aplican sobre grupos de variables definidas según su rol (*all_predictors()*, *all_outcomes(),* etc) o el tipo de variable (*all_numeric()*, *all_nominal()*).

Se genera una receta de preprocesamiento (lm_rec):

```{r}
#incorporamos la fórmula
lm_rec <- recipe(
    ingreso_individual ~ horas_trabajo_domestico +
                         horas_trabajo_mercado +
                         sexo +
                         menores_hogar,
    data = base_juguete
  ) %>% 
  
  step_mutate(
    menores_hogar = as.character(menores_hogar), 
    id="mutate_inicial"
  ) %>% 
  
  #incorporamos transformaciones
  #agrego interacciones entre sexo y todas las variables que empiecen con "horas"
  step_interact(
    ~sexo:starts_with("horas"), 
    id="interacciones"
  ) %>% 
  
  #vuelvo dummy la variable sexo
  step_dummy(sexo, id="dummy") %>% 
  
  #agrupo en niveles que representen al menos el 20% de las observaciones la variable menores_hogar, agrupando a los otros valores en la categoría "otros"
  step_other(menores_hogar, threshold = 0.2, id="other") 
```

Le dimos la base de datos, pero no estimamos nada. Solo necesita la abse de datos para saber qué variables hay y de qué tipo son. Podemos ver cómo quedarán los datos previo al ajuste del modelo:

```{r}
lm_rec %>% 
  prep() %>% #Aplica transformaciones a las variables (hace la cuenta)
  juice()  #Extrae las variables transformadas (nos muestra el resultado)
```

Notemos que ahora la variable cualitativa "menores_hogar" tiene agrupadas a las categorías con pocas observaciones, la dummy "sexo" ya está codificada como "sexo_Mujer", entre otras transformaciones. 

Incorporamos al workflow nuestro nuevo preprocesamiento. Si ya teníamos una fórmula o receta, tenemos que eliminarla para reemplazarla por la nueva.

```{r}
lm_wflow <- lm_wflow %>% 
  
  #se remueve la fórmula anterior ya que ahora la receta contiene la fórmula
  remove_formula() %>% 
  
  #se añade la receta de preprocesamiento
  add_recipe(lm_rec)
```

Luego aplicamos fit:

```{r}
lm_fit4 <- lm_wflow %>% 
  fit(base_juguete)
```

Miremos la performance de este modelo:

```{r}
glance(lm_fit4)
```

Y los coeficientes estimados:

```{r}
lm_fit4 %>% 
  tidy()
```

Vemos que el coeficiente de la interacción entre horas_trabajo_doméstico y sexo es poco significativo, podríamos pensar en sacarlo del modelo.

¿Qué pasó exactamente cuando usamos step_other()?

```{r}
 lm_fit4 %>% 
  extract_recipe(estimated = TRUE) %>% 
  tidy(.,id = "other") #id del step (también es posible buscar por número del step (number=4))
```

Se agrupó a la variable menores_hogar en 4 categorías: 0, 1, 2 y otros.

¿No nos acordamos qué pasos habíamos seguido? Si no, podemos extraerlo:

```{r, results='asis'}
lm_fit4 %>% 
  extract_recipe(estimated = TRUE)
```

# Predicciones

Veamos primero la distribución de los errores y luego la capacidad predictora del modelo

```{r}
lm_fit4 %>% 
augment(new_data = base_juguete) %>%
  mutate(.resid = ingreso_individual - .pred) %>%
  #graficamos
  dplyr::select(.resid, .pred) %>%
  ggplot(aes(x = .pred, y = .resid)) +
    geom_point() +
    theme_minimal() +
    geom_hline(yintercept = 0, linetype = 'dashed') 
```

Comparamos el valor real con nuestra predicción:

```{r}
lm_fit4 %>% 
augment(new_data = base_juguete) %>%
  mutate(.resid = ingreso_individual - .pred) %>%
  dplyr::select(ingreso_individual, .pred, .resid) %>%
  #graficamos
  ggplot(aes(y = .pred, x = ingreso_individual, color = .resid)) +
    geom_point() +
    theme_minimal()  +
    geom_abline(
      intercept = 0,
      slope = 1,
      linewidth = 1,
      color = "grey"
    ) +
    scale_color_viridis(option = "C")
```

¿Dónde predice peor el modelo? ¿Qué se les ocurre que podría hacerse para mejorarlo? ¿Se les ocurre alguna variable que pueda resultar útil?


# Resumen

Al implementar una regresión lineal múltiple:

-   Chequear VIF

-   ¿Qué relaciones son significativas?

-   Interpretación de los coeficientes de las variables cualitativas

-   Transformaciones (codificación, interacciones, etc.)

En tidymodels: usar recipes con workflows. Un workflow podría ser:

```{r}
# Elijo el modelo
lm_model <- linear_reg() %>% 
  set_mode("regression") %>% 
  set_engine("lm")

# Armo mi receta (fórmula y transformaciones)
lm_rec <- recipe(
    ingreso_individual ~ sexo,
    data = base_juguete) %>% 
  step_dummy(sexo, id="dummy") 

# Junto todo en un workflow
lm_wflow <- workflow() %>% 
  add_model(lm_model) %>% 
  add_recipe(lm_rec)

# Estimo
lm_fit <- lm_wflow %>% 
  fit(base_juguete)
  
# Extraigo resultados
lm_fit %>% 
  tidy()

lm_fit %>% 
  augment(base_juguete) %>% select(sexo,ingreso_individual,.pred)
```


# Referencias bibliográficas

- An Introduction to Statistical Learning with applications in R (James, Witten, Hastie y Tibshirani) -- 1st and 2nd version

- Tidy Modeling with R (Kuhn y Silge)

- Introduction to Modern Statistics (Çetinkaya-Rundel y Hardin)
