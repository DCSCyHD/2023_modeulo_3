---
title: "Práctica 5 - Módulo 3"
subtitle: "Implementación de oros modelos de clasificación"
author: 
  - Diplomatura en Ciencias Sociales Computacionales y Humanidades Digitales (IDAES-UNSAM). Marzo/Abril 2023
  - Carolina Pradier y Guido Weksler
output: 
  html_document:
    toc: TRUE
    toc_float:
      toc_collapsed: true
    toc_depth: 3
    number_sections: true
    theme: readable
---

```{r setup, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
knitr::opts_chunk$set(echo=TRUE, message=FALSE, warning=FALSE, tidy=FALSE,
                      fig.width=8)
```

```{r librerias, results='hide'}
library(tidyverse)
library(tidymodels)
library(gt)
library(kableExtra)

options(dplyr.summarise.inform = FALSE)
```


# Introducción       
Este material está destinado a ver la implementación de otros modelos de clasificación supervisada (K-nearest neighbours y Linear Discriminant Analisis) y analizar su performance de manera comparada a la regresión logística.  A su vez, se avanzará sobre ciertas propiedades particulares de estas técnicas. A lo largo del material, repasaremos el enfoque de **train-test** y el trade off existente entre sesgo-varianza a la hora de definir los parámetros de los modelos.   

## Retomando el ejemplo previo           
A los fines de visualizar como opera el modelo de KNN, tomamos la base de juguete y vamos a continuar con el ejemplo de intentar clasificar a quienes realizan trabajo doméstico a partir de 2 predictores:   

 - horas_trabajo_mercado    
 - ingreso_familiar      
 
 
 
```{r}
base_juguete<- readRDS(file = "fuentes/eut_juguete_clase4.RDS") %>% 
  mutate(realiza_trabajo_domestico = factor(realiza_trabajo_domestico)) 

ggplot(base_juguete,aes(x = horas_trabajo_mercado,
                         y = ingreso_familiar,
                         shape = realiza_trabajo_domestico))+
  geom_point(size = 3)
```

# KNN    

## En base completa    
Aunque ya sabemos que no conviene modelar con la base completa, veamos que ocurre al hacerlo de esta manera, para luego pasar a hacer el train-test split.     

<br>

Siguiendo con el lenguaje de tidymodels, para utilizar el método KNN para un modelo de clasificación, podemos aplicar `nearest_neighbor()`, cuyo parametro central es la cantidad de vecinos que queremos considerar. Tiene otros parámetros que permiten cambiar el tipo de distancia, la ponderación que se le da a cada vecino, etc.    

```{r}
knn_model5 <- nearest_neighbor(neighbors = 5,
                                weight_func = "rectangular") %>% # Rectangular es una forma de no asignarle peso a cada una de las distancias
  set_engine("kknn") %>% 
  set_mode("classification") 
 
knn_fiteado5<-  fit(
  object = knn_model5,
  formula = realiza_trabajo_domestico  ~ horas_trabajo_mercado + ingreso_familiar,
  data = base_juguete
  ) 

knn_fiteado5
```
Veamos que ocurre con las predicciones (tomo 50 casos al azar)
```{r}
base_completa_predi <- augment(x = knn_fiteado5, base_juguete) 

base_completa_predi %>% 
  select(realiza_trabajo_domestico,.pred_class,.pred_No,.pred_Si) %>% 
  sample_n(50)
```

<br>

Veamos ahora gráficamente todos los casos. Las predicciones correctas son aquellas en que los Triangulos están en amarillo (realiza TDNR y predigo que lo realiza) y las que los circulos están en violeta (No realiza TDNR y predigo que no lo hace).   

```{r}
ggplot(base_completa_predi,aes(
  x = horas_trabajo_mercado,
  y = ingreso_familiar,
  shape = realiza_trabajo_domestico,
  color = .pred_class))+
  geom_point(size = 3)+
  scale_color_viridis_d()
```
 - **¿Pueden imaginarse una línea de corte viendo el gráfico?**     
 - **¿Como explican lo que pasa con el punto amarillo que destaca arriba?**    
 - **¿Piensan que funciona mejor KNN (respecto a otros modelos) cuando los grupos están bien separados o cuando hay mayor superposición?**      
 
Aclaración: Al predecir sobre el propio dataset completo, cada uno de los puntos está contando como su propio vecino. En una utilización correcta del modelo, prediciendo sobre el test set, esto no ocurrirá.   

<br>
**¿Que pasa a medida que aumentamos K?**
```{r echo=FALSE}

base_juguete_loop <- base_juguete
for(vecinos in c(1,3,5,50)){
  
knn_model <- nearest_neighbor(neighbors = vecinos,weight_func = "rectangular") %>%
  set_engine("kknn") %>% 
  set_mode("classification") 

knn_fiteado<-  fit(object = knn_model,
                   formula = realiza_trabajo_domestico  ~ horas_trabajo_mercado + ingreso_familiar,
                   data = base_juguete)

base_juguete_loop <- augment(x = knn_fiteado, base_juguete_loop)

names(base_juguete_loop)[names(base_juguete_loop) == ".pred_class"] <- paste0("k_",vecinos)

}

base_juguete_loop %>% 
  select(horas_trabajo_mercado,ingreso_familiar,realiza_trabajo_domestico,starts_with("k_")) %>% 
  pivot_longer(cols = starts_with("k_"),names_to = "k_elegido",values_to = ".pred_class") %>% 
ggplot(.,aes(
  x = horas_trabajo_mercado,
  y = ingreso_familiar,
  shape = realiza_trabajo_domestico,
  color = .pred_class))+
  geom_point(size = 3)+
  scale_color_viridis_d()+
  facet_wrap(vars(k_elegido))
```

## Aplicando split traing-test 
```{r}
set.seed(18122022)

base_splietada<- initial_split(base_juguete)
base_train<- training(base_splietada)
base_test<- testing(base_splietada)

knn_fiteado_en_train<-  fit(object = knn_model5,
                   formula = realiza_trabajo_domestico  ~ horas_trabajo_mercado + ingreso_familiar,
                   data = base_train)

base_test_knn <- augment(x = knn_fiteado_en_train, base_test)
 
ggplot(base_test_knn,aes(x = horas_trabajo_mercado,
                         y = ingreso_familiar,
                         shape = realiza_trabajo_domestico,
                         color = .pred_class))+
  geom_point(size = 3)+
  scale_color_viridis_d()

```

## Matriz de confusión y otras métricas
```{r}
conf_mat(data = base_test_knn,truth = realiza_trabajo_domestico,estimate = .pred_class )
accuracy(data = base_test_knn,truth = realiza_trabajo_domestico,estimate = .pred_class )
```

# LDA    
Para correr un modelo de LDA necesitamos un paquete adicional llamado **discrim**. Además de LDA, existen otros modelos "discriminant" no lineales que no veremos en el curso. La función [`discrim_linear()`](https://parsnip.tidymodels.org/reference/discrim_linear.html) es la que determina que utilizaremos la variante lineal. A su vez, dentro de los lineales hay diferentes engines (motores) que se pueden elegir y varían en ciertos parametros adicionales que permiten incluir en el modelo.   

Usaremos el engine default (MASS).   
```{r}
library(discrim)
lda_model <- discrim_linear() 


lda_fiteado<-  fit(object = lda_model,
                   formula = realiza_trabajo_domestico  ~ horas_trabajo_mercado + ingreso_familiar,
                   data = base_train)

base_test_lda <- augment(x = lda_fiteado, base_test)

conf_mat(data = base_test_lda,truth = realiza_trabajo_domestico,estimate = .pred_class )
accuracy(data = base_test_lda,truth = realiza_trabajo_domestico,estimate = .pred_class )
```

# Práctica (en clase)     
 - Estimen 2 modelos con las variables de la base de juguete:
    - Un KNN con K = 3
    - Una regresión logística (como la de la clase pasada)  
 - Comparen el accuracy (tanto en training como en testing) de estos 2 modelos con el de LDA recién visto

