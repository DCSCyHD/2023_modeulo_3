---
title: "Práctica 5 - Módulo 3"
subtitle: "Implementación de otros modelos de clasificación"
author: 
  - Diplomatura en Ciencias Sociales Computacionales y Humanidades Digitales (IDAES-UNSAM)
output: 
  html_document:
    toc: TRUE
    toc_float:
      toc_collapsed: true
    toc_depth: 3
    number_sections: true
    theme: readable
editor_options: 
  chunk_output_type: console
---

\> Material elaborado originalmente por Carolina Pradier y Guido Weksler

```{r setup, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  message = FALSE,
  warning = FALSE,
  tidy = FALSE,
  fig.width = 8
)
```

```{r librerias, results='hide'}
library(tidyverse)
library(tidymodels)
library(gt)
library(kableExtra)
library(discrim)
library(kknn)
library(naivebayes)
library(patchwork) # Visualizar múltiples plots juntos


options(dplyr.summarise.inform = FALSE, scipen = 999)
shape_values = c(4,1)
theme_set(theme_bw())
```

# Introducción

Este material está destinado a ver la implementación de otros modelos de clasificación supervisada (K-nearest neighbours y Linear Discriminant Analisis) y analizar su performance de manera comparada a la regresión logística. A su vez, se avanzará sobre ciertas propiedades particulares de estas técnicas. A lo largo del material, repasaremos el enfoque de **train-test** y el trade off existente entre sesgo-varianza a la hora de definir los parámetros de los modelos.

## Retomando el ejemplo previo

A los fines de visualizar cómo opera el modelo de KNN, tomamos la base de juguete y vamos a continuar con el ejemplo de intentar clasificar a quienes realizan trabajo doméstico a partir de 2 predictores:

-   horas_trabajo_mercado

-   ingreso_familiar

```{r}
base_juguete <- readRDS(file = "fuentes/eut_juguete_clase4.RDS") %>%
  mutate(realiza_trabajo_domestico = factor(realiza_trabajo_domestico,
                                            levels = c("Si", "No")))

base_juguete %>%
  ggplot(
    aes(x = horas_trabajo_mercado,
        y = ingreso_familiar,
        shape = realiza_trabajo_domestico)
  ) +
  geom_point(size = 3)+
  scale_shape_manual(values=shape_values)

```

# KNN

## En base completa

Aunque ya sabemos que no conviene modelar con la base completa, veamos que ocurre al hacerlo de esta manera, para luego pasar a hacer el train-test split.

<br>

Siguiendo con el lenguaje de tidymodels, para utilizar el método KNN para un modelo de clasificación, podemos aplicar `nearest_neighbor()`, cuyo parametro central es la cantidad de vecinos que queremos considerar. Tiene otros parámetros que permiten cambiar el tipo de distancia, la ponderación que se le da a cada vecino, etc. El engine correspondiente es "kknn".

<br> **Aclaración**: Por un error de tidymodels, si queremos correr KNN con variables explicativas categóricas debemos cargar adicionalmente el paquete "kknn". <br>

```{r}
knn_model5 <- nearest_neighbor(
    neighbors = 5,
    weight_func = "rectangular" #Sin asignar peso a las distancias
  ) %>% 
  set_engine("kknn") %>% 
  set_mode("classification")
```

```{r}
knn_fit <-  fit(
  object = knn_model5,
  formula = realiza_trabajo_domestico  ~ horas_trabajo_mercado +
                                         ingreso_familiar,
  data = base_juguete
)

```

Veamos que ocurre con las predicciones (tomo 50 casos al azar)

```{r}
base_pred <- knn_fit %>% 
  augment(base_juguete) 

set.seed(42)
base_pred %>% 
  select(realiza_trabajo_domestico,.pred_class,.pred_No,.pred_Si) %>% 
  sample_n(50)
```

<br>

Veamos ahora gráficamente todos los casos. Las predicciones correctas son aquellas en que las cruces están en rojo (realiza TDNR y predigo que lo realiza) y las que los circulos están en azul (no realiza TDNR y predigo que no lo hace).

```{r}
ggplot(
    base_pred,
    aes(
      x = horas_trabajo_mercado,
      y = ingreso_familiar,
      shape = realiza_trabajo_domestico,
      color = .pred_class
    )
  ) +
  geom_point(size = 3) +
  scale_shape_manual(values=shape_values)+
  scale_color_manual(values=c("red","blue"))
```

-   **¿Pueden imaginarse una frontera de decisión viendo el gráfico?**\
-   **¿Como explican lo que pasa con el punto clasificado erróneamente arriba a la derecha?**\
-   **¿Piensan que funciona mejor KNN (respecto a otros modelos) cuando los grupos están bien separados o cuando hay mayor superposición?**

Aclaración: Al predecir sobre el propio dataset completo, cada uno de los puntos está contando como su propio vecino. En una utilización correcta del modelo, prediciendo sobre el test set, esto no ocurrirá.

<br> **¿Que pasa a medida que aumentamos K?**

En la práctica no vamos a necesitar este paso, pero para respondernos esta pregunta podemos usar un loop para estimar el modelo para varios valores de k. 

```{r echo=FALSE}
base_juguete_loop <- base_juguete

for (k in c(1, 3, 5, 50)) {
  knn_modelk <- nearest_neighbor(neighbors = k, weight_func = "rectangular") %>%
    set_engine("kknn") %>%
    set_mode("classification")
  
  knn_fitk <-  fit(
    object = knn_modelk,
    formula = realiza_trabajo_domestico  ~ horas_trabajo_mercado +
                                           ingreso_familiar,
    data = base_juguete
  )
  
  preds <- knn_fitk %>% 
    predict(base_juguete_loop)

  base_juguete_loop[,paste0("k_",k)] = preds
  
  names(base_juguete_loop)[names(base_juguete_loop) == ".pred_class"] <-
    paste0("k_", k)
  
}
```

Ahora armamos un dataframe cómo para graficar y mostramos los resultados para cada valor de k.

```{r echo=FALSE}
base_juguete_loop %>%
  select(
    horas_trabajo_mercado,
    ingreso_familiar,
    realiza_trabajo_domestico,
    starts_with("k_")
  ) %>%
  pivot_longer(cols = starts_with("k_"),
               names_to = "k_elegido",
               values_to = ".pred_class") %>%
  ggplot(
    .,
    aes(
      x = horas_trabajo_mercado,
      y = ingreso_familiar,
      shape = realiza_trabajo_domestico,
      color = .pred_class
    )
  ) +
  geom_point(size = 3) +
  facet_wrap(vars(k_elegido))+
  scale_shape_manual(values=shape_values)+
  scale_color_manual(values=c("red","blue"))
```

## Aplicando split traing-test

```{r}
# Split
set.seed(132)

base_split <- initial_split(base_juguete)
base_train <- training(base_split)
base_test <- testing(base_split)

# Estimo con train
knn_fit_train <-  knn_model5 %>% 
  fit(formula = realiza_trabajo_domestico  ~ horas_trabajo_mercado + 
                                             ingreso_familiar,
      data = base_train)

# Aplico a test
knn_fit_test <- knn_fit_train %>% 
  augment(base_test)

ggplot(
  knn_fit_test,
  aes(
    x = horas_trabajo_mercado,
    y = ingreso_familiar,
    shape = realiza_trabajo_domestico,
    color = .pred_class
  )
) +
  geom_point(size = 3) +
  scale_shape_manual(values=shape_values)+
  scale_color_manual(values=c("red","blue"))

```

## Matriz de confusión y otras métricas

```{r}
cm <- conf_mat(data = knn_fit_test,
               truth = realiza_trabajo_domestico,
               estimate = .pred_class )

cm %>% autoplot("heatmap")+scale_fill_viridis_b(alpha = .3)
```

```{r}
accuracy(data = knn_fit_test,
         truth = realiza_trabajo_domestico,
         estimate = .pred_class)
```

# LDA

Para correr un modelo de LDA necesitamos un paquete adicional llamado **discrim**. La función [`discrim_linear()`](https://parsnip.tidymodels.org/reference/discrim_linear.html) es la que determina que utilizaremos la variante lineal. A su vez, dentro de los lineales hay diferentes engines (motores) que se pueden elegir y varían en ciertos parametros adicionales que permiten incluir en el modelo. Usamos el engine default (MASS).

```{r}
lda_model <- discrim_linear() %>% 
  set_engine("MASS") %>% 
  set_mode("classification") 
  

lda_fit <-  lda_model %>% 
  fit(formula = realiza_trabajo_domestico  ~ horas_trabajo_mercado + 
                                             ingreso_familiar,
      data = base_train)

lda_fit_test <- lda_fit %>% 
  augment(base_test)

conf_mat(data = lda_fit_test,
         truth = realiza_trabajo_domestico,
         estimate = .pred_class)

accuracy(data = lda_fit_test,
         truth = realiza_trabajo_domestico,
         estimate = .pred_class)
```

Para estimar un QDA reemplazaríamos `discrim_linear()` por `discrim_quad()`.

# Naive bayes

Para estimar naive Bayes, usamos `naive_Bayes()`, con el engine correspondiente.

```{r}
nb_model <- naive_Bayes() %>%
  set_engine('naivebayes') %>% 
  set_mode("classification")

nb_fit <-  nb_model %>%
  fit(formula = realiza_trabajo_domestico  ~ horas_trabajo_mercado +
                                             ingreso_familiar,
      data = base_train)

```

# Regresión logística

Agreguemos una regresión logística (como la de la clase pasada).

```{r}
log_model <-  logistic_reg() %>%
  set_mode("classification") %>% 
  set_engine("glm")

log_fit <- log_model %>% 
  fit(formula = realiza_trabajo_domestico  ~ horas_trabajo_mercado +
                                             ingreso_familiar,
      data = base_train)

```


# Comparando modelos

Una de las potencialidades de **tidymodels** es que nos permite con mucha facilidad comparar métricas de cada uno de los modelos.\

Se crea una lista de todos los modelos a evaluar, puedo luego con la función `imap_dfr` pasar cada uno de estos modelos como argumento de la función **augment()** y así agregar las predicciones de cada modelo al set de testing.

```{r}
#Lista de modelos
modelos <- list("logistica" = log_fit,
                "LDA" = lda_fit,
                "KNN-5" = knn_fit, 
                "Naive bayes" = nb_fit
            )

names(modelos)

```

La función imap_dfr permite aplicar la función augment a una lista de modelos, considerando la data de evaluación (base_test).

```{r}
base_test_preds <- imap_dfr(modelos,
                            augment,
                            new_data = base_test,
                            .id = "model")

#Visualizando las columnas generadas
base_test_preds %>%
  select(model,
         realiza_trabajo_domestico,
         .pred_class,
         .pred_No,
         .pred_Si) %>% 
  sample_n(10)
```

La función **metric_set()** nos permite establecer un conjunto de metricas de interés que luego podemos aplicar sobre nuestros modelos para compararlos.

```{r}
multi_metric <- metric_set(accuracy, sensitivity, specificity)

```

Para aplicarlas a cada modelo hay que agrupar por modelo.

```{r}
base_test_preds %>%
  group_by(model) %>%
  multi_metric(truth = realiza_trabajo_domestico,
               estimate = .pred_class) %>% 
  arrange(.metric, .estimate)
```

# Visualmente

Luego de haber revisado las métricas, se encontraron diferencias en la performance de distintos modelos. En este punto, vamos a realizar una simulación de N observaciones para visualizar la frontera de decisión de cada uno de los modelos (decision boundary).

```{r, fig.width=10, fig.height=10}
source("plot_decision_boundary.R")
p_knn5 <- plot_decision_boundary(
  data = base_juguete,
  model = knn_fit,
  x_names = c("horas_trabajo_mercado", "ingreso_familiar"),
  y_name = "realiza_trabajo_domestico",
  n_points = 100,
  model_name = "KNN (k=5)"
)

p_lda <- plot_decision_boundary(
  data = base_juguete,
  model = lda_fit,
  x_names = c("horas_trabajo_mercado", "ingreso_familiar"),
  y_name = "realiza_trabajo_domestico",
  n_points = 100,
  model_name = "LDA"
)

p_log <- plot_decision_boundary(
  data = base_juguete,
  model = log_fit,
  x_names = c("horas_trabajo_mercado", "ingreso_familiar"),
  y_name = "realiza_trabajo_domestico",
  n_points = 100,
  model_name = "Regresión logística"
)

p_nb <- plot_decision_boundary(
  data = base_juguete,
  model = nb_fit,
  x_names = c("horas_trabajo_mercado", "ingreso_familiar"),
  y_name = "realiza_trabajo_domestico",
  n_points = 500,
  model_name = "Naive Bayes"
)

(p_knn5 | p_lda) / (p_log | p_nb)
```

Se observa que el modelo KNN (k=5) tiene una frontera más flexible, mientras que los modelos LDA y regresión logística muestran una frontera de decisión lineal.

Notar que, aunque la regresión logística y el modelo LDA son similares, no son iguales y por eso se observaban métricas diferentes en el punto anterior.

# Resumen

Se ajustaron 4 tipos de modelos distintos.

-   KNN

-   LDA

-   Regresión logística

-   Naive bayes

